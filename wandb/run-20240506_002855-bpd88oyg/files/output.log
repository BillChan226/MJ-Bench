





















































Timestep:  96%|████████████████████████████████████████████████████████████████████████████████████████▎   | 48/50 [00:33<00:01,  1.42it/s]

















Timestep:  96%|████████████████████████████████████████████████████████████████████████████████████████▎   | 48/50 [00:33<00:01,  1.42it/s]
images.shape torch.Size([16, 3, 512, 512])
images.shape torch.Size([16, 3, 512, 512])
images.shape torch.Size([16, 3, 512, 512])
images.shape torch.Size([16, 3, 512, 512])
                                                                                                                                           Traceback (most recent call last):
  File "experimental/ddpo_finetune.py", line 140, in <module>
    trainer.train()
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/trl/trainer/ddpo_trainer.py", line 604, in train
    global_step = self.step(epoch, global_step)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/trl/trainer/ddpo_trainer.py", line 328, in step
    global_step = self._train_batched_samples(inner_epoch, epoch, global_step, samples_batched)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/trl/trainer/ddpo_trainer.py", line 535, in _train_batched_samples
    loss, approx_kl, clipfrac = self.calculate_loss(
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/trl/trainer/ddpo_trainer.py", line 365, in calculate_loss
    noise_pred = self.sd_pipeline.unet(
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/accelerate/utils/operations.py", line 825, in forward
    return model_forward(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/accelerate/utils/operations.py", line 813, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_condition.py", line 1281, in forward
    sample = upsample_block(
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_blocks.py", line 2542, in forward
    hidden_states = attn(
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/transformers/transformer_2d.py", line 397, in forward
    hidden_states = block(
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/attention.py", line 392, in forward
    ff_output = self.ff(norm_hidden_states)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/attention.py", line 664, in forward
    hidden_states = module(hidden_states)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/activations.py", line 103, in forward
    return hidden_states * self.gelu(gate)
  File "/home/czr/anaconda3/envs/MM/lib/python3.8/site-packages/diffusers/models/activations.py", line 93, in gelu
    return F.gelu(gate)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 147.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 218.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)