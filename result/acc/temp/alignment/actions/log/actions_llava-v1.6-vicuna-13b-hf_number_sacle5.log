2024-05-30 20:50:44 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 20:50:47 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.06s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.00s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.02it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.03it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.23it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 20:50:54 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:19, 19.14s/it]Evaluating RM: : 2it [00:33, 16.56s/it]Evaluating RM: : 3it [00:47, 15.43s/it]Evaluating RM: : 4it [01:04, 15.77s/it]Evaluating RM: : 5it [01:37, 22.02s/it]Evaluating RM: : 6it [01:53, 20.16s/it]Evaluating RM: : 7it [02:04, 17.15s/it]Evaluating RM: : 8it [02:14, 14.66s/it]Evaluating RM: : 9it [02:26, 14.03s/it]Evaluating RM: : 10it [02:38, 13.44s/it]Evaluating RM: : 11it [02:50, 12.91s/it]Evaluating RM: : 12it [03:19, 17.80s/it]Evaluating RM: : 13it [03:52, 22.46s/it]Evaluating RM: : 14it [04:01, 18.43s/it]Evaluating RM: : 15it [04:24, 19.56s/it]Evaluating RM: : 16it [04:38, 18.15s/it]Evaluating RM: : 17it [05:00, 19.09s/it]Evaluating RM: : 18it [05:10, 16.53s/it]Evaluating RM: : 19it [05:27, 16.54s/it]Evaluating RM: : 20it [05:40, 15.46s/it]Evaluating RM: : 21it [05:50, 13.91s/it]Evaluating RM: : 22it [06:01, 13.12s/it]Evaluating RM: : 23it [06:19, 14.35s/it]Evaluating RM: : 24it [06:35, 14.83s/it]Evaluating RM: : 25it [06:51, 15.36s/it]Evaluating RM: : 26it [07:09, 15.99s/it]Evaluating RM: : 27it [07:21, 14.89s/it]Evaluating RM: : 28it [07:39, 15.77s/it]2024-05-30 20:58:58 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 28
Evaluating RM: : 29it [08:04, 18.65s/it]Evaluating RM: : 30it [08:32, 21.46s/it]Evaluating RM: : 31it [08:44, 18.66s/it]Evaluating RM: : 32it [08:54, 16.05s/it]Evaluating RM: : 33it [09:25, 20.46s/it]Evaluating RM: : 34it [09:36, 17.75s/it]Evaluating RM: : 35it [10:05, 20.89s/it]Evaluating RM: : 36it [10:17, 18.34s/it]Evaluating RM: : 37it [10:37, 18.80s/it]Evaluating RM: : 38it [10:50, 16.98s/it]Evaluating RM: : 39it [11:02, 15.54s/it]Evaluating RM: : 40it [11:17, 15.36s/it]Evaluating RM: : 41it [11:31, 15.07s/it]Evaluating RM: : 42it [11:43, 14.15s/it]Evaluating RM: : 43it [11:54, 13.16s/it]Evaluating RM: : 44it [12:12, 14.63s/it]Evaluating RM: : 45it [12:32, 16.14s/it]Evaluating RM: : 46it [12:46, 15.62s/it]Evaluating RM: : 47it [13:06, 16.91s/it]Evaluating RM: : 48it [13:20, 15.95s/it]Evaluating RM: : 49it [13:41, 17.43s/it]Evaluating RM: : 50it [14:02, 18.65s/it]Evaluating RM: : 51it [14:20, 18.49s/it]Evaluating RM: : 52it [14:32, 16.31s/it]Evaluating RM: : 53it [15:00, 20.06s/it]Evaluating RM: : 54it [15:34, 24.24s/it]Evaluating RM: : 55it [15:54, 22.92s/it]Evaluating RM: : 56it [16:13, 21.55s/it]Evaluating RM: : 57it [16:35, 21.76s/it]Evaluating RM: : 58it [17:06, 24.54s/it]Evaluating RM: : 59it [17:15, 19.83s/it]2024-05-30 21:08:30 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 59
Evaluating RM: : 60it [17:36, 20.39s/it]Evaluating RM: : 61it [17:47, 17.34s/it]Evaluating RM: : 62it [18:03, 17.00s/it]Evaluating RM: : 63it [18:13, 14.98s/it]Evaluating RM: : 64it [18:29, 15.25s/it]Evaluating RM: : 65it [18:42, 14.75s/it]Evaluating RM: : 66it [19:06, 17.25s/it]Evaluating RM: : 67it [19:33, 20.34s/it]Evaluating RM: : 68it [19:48, 18.78s/it]Evaluating RM: : 69it [20:16, 21.31s/it]Evaluating RM: : 70it [20:33, 20.27s/it]Evaluating RM: : 71it [20:55, 20.67s/it]Evaluating RM: : 72it [21:08, 18.39s/it]Evaluating RM: : 73it [21:22, 17.07s/it]Evaluating RM: : 74it [21:41, 17.70s/it]Evaluating RM: : 75it [21:55, 16.44s/it]Evaluating RM: : 76it [22:13, 17.09s/it]Evaluating RM: : 77it [22:29, 16.76s/it]Evaluating RM: : 78it [22:48, 17.46s/it]Evaluating RM: : 79it [23:08, 18.24s/it]Evaluating RM: : 80it [23:18, 15.70s/it]Evaluating RM: : 81it [23:30, 14.45s/it]Evaluating RM: : 82it [23:43, 14.23s/it]Evaluating RM: : 83it [24:04, 16.27s/it]Evaluating RM: : 84it [24:13, 14.02s/it]Evaluating RM: : 85it [24:24, 13.17s/it]Evaluating RM: : 86it [24:41, 14.11s/it]Evaluating RM: : 87it [25:00, 15.55s/it]Evaluating RM: : 88it [25:11, 14.14s/it]Evaluating RM: : 89it [25:22, 13.22s/it]Evaluating RM: : 90it [25:33, 12.73s/it]Evaluating RM: : 91it [25:47, 13.17s/it]Evaluating RM: : 92it [26:05, 14.46s/it]Evaluating RM: : 93it [26:29, 17.26s/it]Evaluating RM: : 94it [27:01, 21.77s/it]Evaluating RM: : 95it [27:18, 20.29s/it]Evaluating RM: : 96it [27:30, 17.96s/it]Evaluating RM: : 97it [27:50, 18.35s/it]Evaluating RM: : 98it [28:05, 17.60s/it]Evaluating RM: : 99it [28:16, 15.64s/it]Evaluating RM: : 100it [28:31, 15.42s/it]Evaluating RM: : 101it [28:41, 13.68s/it]Evaluating RM: : 102it [28:50, 12.30s/it]Evaluating RM: : 103it [29:01, 11.84s/it]Evaluating RM: : 104it [29:13, 11.89s/it]Evaluating RM: : 105it [29:35, 14.84s/it]Evaluating RM: : 106it [29:46, 13.82s/it]Evaluating RM: : 107it [30:19, 19.49s/it]Evaluating RM: : 108it [30:31, 17.23s/it]Evaluating RM: : 109it [30:46, 16.81s/it]Evaluating RM: : 110it [31:03, 16.83s/it]Evaluating RM: : 111it [31:15, 15.42s/it]Evaluating RM: : 112it [31:28, 14.43s/it]Evaluating RM: : 113it [31:43, 14.85s/it]Evaluating RM: : 114it [31:51, 12.75s/it]2024-05-30 21:23:19 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 114
Evaluating RM: : 115it [32:25, 19.00s/it]Evaluating RM: : 116it [32:35, 16.39s/it]2024-05-30 21:23:47 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 116
Evaluating RM: : 117it [32:53, 16.75s/it]Evaluating RM: : 117it [32:53, 16.87s/it]
2024-05-30 21:23:47 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/actions
