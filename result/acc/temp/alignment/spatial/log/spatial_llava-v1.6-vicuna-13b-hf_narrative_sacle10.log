2024-05-30 22:36:56 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 22:37:00 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.07it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.13it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.13it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.11it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.21it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 22:37:05 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_narrative_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:18, 18.50s/it]Evaluating RM: : 2it [00:31, 15.19s/it]Evaluating RM: : 3it [00:44, 14.06s/it]2024-05-30 22:38:03 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 3
Evaluating RM: : 4it [00:57, 13.67s/it]Evaluating RM: : 5it [01:08, 12.96s/it]Evaluating RM: : 6it [01:20, 12.61s/it]Evaluating RM: : 7it [01:30, 11.63s/it]Evaluating RM: : 8it [01:50, 14.42s/it]Evaluating RM: : 9it [02:05, 14.50s/it]Evaluating RM: : 10it [02:20, 14.78s/it]Evaluating RM: : 11it [02:30, 13.23s/it]Evaluating RM: : 12it [02:41, 12.53s/it]Evaluating RM: : 13it [02:54, 12.69s/it]Evaluating RM: : 14it [03:09, 13.37s/it]Evaluating RM: : 15it [03:18, 12.04s/it]Evaluating RM: : 16it [03:36, 13.70s/it]Evaluating RM: : 17it [03:52, 14.57s/it]Evaluating RM: : 18it [04:10, 15.55s/it]Evaluating RM: : 19it [04:21, 14.31s/it]Evaluating RM: : 20it [04:31, 13.03s/it]Evaluating RM: : 21it [04:42, 12.26s/it]2024-05-30 22:42:00 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 21
Evaluating RM: : 22it [04:54, 12.26s/it]Evaluating RM: : 23it [05:10, 13.42s/it]Evaluating RM: : 24it [05:22, 12.81s/it]Evaluating RM: : 25it [05:35, 13.02s/it]Evaluating RM: : 26it [05:54, 14.62s/it]Evaluating RM: : 27it [06:10, 15.10s/it]Evaluating RM: : 28it [06:35, 18.16s/it]Evaluating RM: : 29it [06:55, 18.56s/it]Evaluating RM: : 30it [07:05, 16.11s/it]Evaluating RM: : 31it [07:16, 14.61s/it]Evaluating RM: : 32it [07:26, 13.19s/it]Evaluating RM: : 33it [07:59, 19.09s/it]Evaluating RM: : 34it [08:16, 18.48s/it]Evaluating RM: : 35it [08:33, 17.98s/it]2024-05-30 22:46:04 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 35
Evaluating RM: : 36it [08:58, 20.21s/it]2024-05-30 22:46:18 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 36
Evaluating RM: : 37it [09:12, 18.35s/it]Evaluating RM: : 38it [09:30, 18.26s/it]Evaluating RM: : 39it [09:39, 15.34s/it]2024-05-30 22:47:08 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 39
Evaluating RM: : 40it [10:02, 17.77s/it]2024-05-30 22:47:21 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 40
Evaluating RM: : 41it [10:15, 16.42s/it]Evaluating RM: : 42it [10:43, 19.92s/it]Evaluating RM: : 43it [10:55, 17.50s/it]Evaluating RM: : 44it [11:04, 14.98s/it]Evaluating RM: : 45it [11:14, 13.36s/it]Evaluating RM: : 46it [11:28, 13.61s/it]Evaluating RM: : 47it [11:37, 12.18s/it]Evaluating RM: : 48it [11:52, 13.16s/it]Evaluating RM: : 49it [12:04, 12.75s/it]Evaluating RM: : 50it [12:21, 13.90s/it]Evaluating RM: : 51it [12:44, 16.62s/it]Evaluating RM: : 52it [12:54, 14.55s/it]2024-05-30 22:50:25 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 52
Evaluating RM: : 53it [13:19, 17.97s/it]Evaluating RM: : 54it [13:32, 16.48s/it]Evaluating RM: : 55it [13:44, 14.89s/it]Evaluating RM: : 56it [13:55, 13.81s/it]Evaluating RM: : 57it [14:04, 12.46s/it]Evaluating RM: : 58it [14:12, 11.19s/it]Evaluating RM: : 59it [14:23, 10.96s/it]Evaluating RM: : 60it [14:31, 10.15s/it]Evaluating RM: : 61it [14:40,  9.81s/it]Evaluating RM: : 62it [14:53, 10.57s/it]Evaluating RM: : 63it [15:08, 12.18s/it]Evaluating RM: : 64it [15:20, 12.10s/it]Evaluating RM: : 65it [15:31, 11.76s/it]Evaluating RM: : 66it [15:42, 11.56s/it]Evaluating RM: : 67it [15:55, 11.79s/it]Evaluating RM: : 68it [16:13, 13.68s/it]Evaluating RM: : 69it [16:22, 12.22s/it]Evaluating RM: : 70it [16:31, 11.47s/it]Evaluating RM: : 71it [16:50, 13.52s/it]Evaluating RM: : 72it [16:59, 12.12s/it]Evaluating RM: : 73it [17:09, 11.58s/it]Evaluating RM: : 74it [17:25, 12.94s/it]Evaluating RM: : 75it [17:39, 13.23s/it]Evaluating RM: : 76it [18:09, 18.26s/it]Evaluating RM: : 77it [18:21, 16.47s/it]Evaluating RM: : 77it [18:21, 14.31s/it]
2024-05-30 22:55:27 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/spatial
