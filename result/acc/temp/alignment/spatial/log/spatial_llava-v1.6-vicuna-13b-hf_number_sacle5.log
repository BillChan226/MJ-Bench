2024-05-30 22:55:14 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 22:55:17 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.14it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.16it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.17it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.19it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.28it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 22:55:23 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:18, 18.49s/it]Evaluating RM: : 2it [00:36, 18.35s/it]Evaluating RM: : 3it [00:48, 15.47s/it]Evaluating RM: : 4it [01:00, 13.97s/it]Evaluating RM: : 5it [01:09, 12.21s/it]Evaluating RM: : 6it [01:21, 12.25s/it]Evaluating RM: : 7it [01:31, 11.44s/it]2024-05-30 22:57:17 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 7
Evaluating RM: : 8it [01:54, 15.05s/it]Evaluating RM: : 9it [02:04, 13.62s/it]Evaluating RM: : 10it [02:17, 13.39s/it]Evaluating RM: : 11it [02:27, 12.42s/it]Evaluating RM: : 12it [02:39, 12.05s/it]Evaluating RM: : 13it [02:58, 14.13s/it]Evaluating RM: : 14it [03:13, 14.65s/it]Evaluating RM: : 15it [03:21, 12.65s/it]Evaluating RM: : 16it [03:38, 13.82s/it]Evaluating RM: : 17it [03:50, 13.34s/it]Evaluating RM: : 18it [04:06, 14.04s/it]Evaluating RM: : 19it [04:17, 13.11s/it]Evaluating RM: : 20it [04:40, 16.25s/it]Evaluating RM: : 21it [04:59, 16.82s/it]Evaluating RM: : 22it [05:08, 14.74s/it]Evaluating RM: : 23it [05:26, 15.72s/it]Evaluating RM: : 24it [05:38, 14.56s/it]Evaluating RM: : 25it [05:51, 13.89s/it]Evaluating RM: : 26it [06:10, 15.66s/it]Evaluating RM: : 27it [06:24, 14.89s/it]Evaluating RM: : 28it [06:37, 14.35s/it]Evaluating RM: : 29it [06:52, 14.75s/it]Evaluating RM: : 30it [07:14, 16.74s/it]Evaluating RM: : 31it [07:25, 15.07s/it]Evaluating RM: : 32it [07:42, 15.68s/it]Evaluating RM: : 33it [08:12, 19.97s/it]2024-05-30 23:03:56 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 33
Evaluating RM: : 34it [08:33, 20.21s/it]Evaluating RM: : 35it [08:56, 21.22s/it]Evaluating RM: : 36it [09:27, 24.08s/it]Evaluating RM: : 37it [09:42, 21.24s/it]Evaluating RM: : 38it [09:51, 17.62s/it]Evaluating RM: : 39it [10:00, 15.07s/it]Evaluating RM: : 40it [10:11, 13.82s/it]Evaluating RM: : 41it [10:38, 17.79s/it]Evaluating RM: : 42it [10:57, 18.08s/it]Evaluating RM: : 43it [11:10, 16.70s/it]Evaluating RM: : 44it [11:19, 14.29s/it]Evaluating RM: : 45it [11:31, 13.57s/it]Evaluating RM: : 46it [11:52, 15.86s/it]Evaluating RM: : 47it [12:10, 16.45s/it]Evaluating RM: : 48it [12:30, 17.72s/it]Evaluating RM: : 49it [12:46, 17.02s/it]Evaluating RM: : 50it [13:02, 16.84s/it]Evaluating RM: : 51it [13:21, 17.48s/it]Evaluating RM: : 52it [13:38, 17.26s/it]Evaluating RM: : 53it [13:58, 18.07s/it]Evaluating RM: : 54it [14:09, 15.97s/it]Evaluating RM: : 55it [14:18, 14.00s/it]Evaluating RM: : 56it [14:35, 14.65s/it]Evaluating RM: : 57it [14:53, 15.91s/it]Evaluating RM: : 58it [15:04, 14.25s/it]Evaluating RM: : 59it [15:14, 12.97s/it]Evaluating RM: : 60it [15:24, 12.12s/it]Evaluating RM: : 61it [15:33, 11.32s/it]Evaluating RM: : 62it [15:48, 12.44s/it]Evaluating RM: : 63it [16:04, 13.42s/it]Evaluating RM: : 64it [16:14, 12.27s/it]Evaluating RM: : 65it [16:24, 11.75s/it]Evaluating RM: : 66it [16:33, 10.93s/it]Evaluating RM: : 67it [16:45, 11.07s/it]Evaluating RM: : 68it [16:55, 10.90s/it]Evaluating RM: : 69it [17:06, 10.99s/it]Evaluating RM: : 70it [17:18, 11.31s/it]Evaluating RM: : 71it [17:31, 11.55s/it]Evaluating RM: : 72it [17:41, 11.36s/it]2024-05-30 23:13:38 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 72
Evaluating RM: : 73it [18:15, 17.97s/it]Evaluating RM: : 74it [18:28, 16.56s/it]Evaluating RM: : 75it [18:41, 15.49s/it]Evaluating RM: : 76it [18:51, 13.94s/it]2024-05-30 23:14:32 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 76
Evaluating RM: : 77it [19:09, 15.01s/it]Evaluating RM: : 77it [19:09, 14.93s/it]
2024-05-30 23:14:32 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/spatial
