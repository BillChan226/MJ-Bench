2024-05-30 21:31:07 | INFO | alignment_rm_score | Loading reward model form llava-1.5-13b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.45it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.72it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  1.77it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.82it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:02<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  2.21it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:31:18 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:15, 15.56s/it]Evaluating RM: : 2it [00:27, 13.56s/it]Evaluating RM: : 3it [00:40, 13.10s/it]Evaluating RM: : 4it [00:55, 13.75s/it]Evaluating RM: : 5it [01:11, 14.55s/it]Evaluating RM: : 6it [01:25, 14.58s/it]Evaluating RM: : 7it [01:38, 13.89s/it]Evaluating RM: : 8it [01:48, 12.73s/it]Evaluating RM: : 9it [02:00, 12.56s/it]Evaluating RM: : 10it [02:14, 13.00s/it]Evaluating RM: : 11it [02:25, 12.38s/it]Evaluating RM: : 12it [02:39, 12.98s/it]Evaluating RM: : 13it [02:51, 12.49s/it]Evaluating RM: : 14it [03:03, 12.32s/it]Evaluating RM: : 15it [03:14, 11.89s/it]Evaluating RM: : 16it [03:25, 11.64s/it]Evaluating RM: : 17it [03:37, 11.93s/it]Evaluating RM: : 18it [03:49, 11.76s/it]Evaluating RM: : 19it [04:03, 12.59s/it]Evaluating RM: : 20it [04:16, 12.63s/it]Evaluating RM: : 21it [04:27, 12.16s/it]Evaluating RM: : 22it [04:39, 12.24s/it]Evaluating RM: : 23it [04:54, 13.05s/it]Evaluating RM: : 24it [05:14, 15.10s/it]Evaluating RM: : 25it [05:28, 14.73s/it]Evaluating RM: : 26it [05:40, 13.94s/it]Evaluating RM: : 27it [05:55, 14.10s/it]Evaluating RM: : 28it [06:13, 15.50s/it]Evaluating RM: : 29it [06:28, 15.21s/it]Evaluating RM: : 30it [06:39, 13.87s/it]Evaluating RM: : 31it [06:52, 13.77s/it]Evaluating RM: : 32it [07:06, 13.78s/it]Evaluating RM: : 33it [07:17, 13.07s/it]Evaluating RM: : 34it [07:29, 12.66s/it]Evaluating RM: : 35it [07:41, 12.33s/it]Evaluating RM: : 36it [07:52, 12.04s/it]Evaluating RM: : 37it [08:03, 11.64s/it]Evaluating RM: : 38it [08:14, 11.54s/it]Evaluating RM: : 39it [08:27, 12.08s/it]Evaluating RM: : 40it [08:40, 12.34s/it]Evaluating RM: : 41it [08:51, 11.72s/it]Evaluating RM: : 42it [09:05, 12.43s/it]Evaluating RM: : 43it [09:16, 12.18s/it]Evaluating RM: : 44it [09:29, 12.28s/it]Evaluating RM: : 45it [09:44, 13.12s/it]Evaluating RM: : 46it [09:55, 12.63s/it]Evaluating RM: : 47it [10:11, 13.60s/it]Evaluating RM: : 48it [10:23, 13.11s/it]Evaluating RM: : 49it [10:34, 12.38s/it]Evaluating RM: : 50it [10:46, 12.25s/it]Evaluating RM: : 51it [10:57, 11.83s/it]Evaluating RM: : 52it [11:11, 12.65s/it]Evaluating RM: : 53it [11:26, 13.30s/it]Evaluating RM: : 54it [11:40, 13.40s/it]Evaluating RM: : 55it [11:49, 12.15s/it]Evaluating RM: : 56it [12:01, 12.20s/it]Evaluating RM: : 56it [12:01, 12.89s/it]
2024-05-30 21:43:20 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
