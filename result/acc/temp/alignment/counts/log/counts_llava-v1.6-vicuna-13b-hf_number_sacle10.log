2024-05-30 21:53:55 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 21:53:59 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.09it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.09it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.08it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.07it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.08it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 21:54:05 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:11, 11.72s/it]Evaluating RM: : 2it [00:21, 10.84s/it]Evaluating RM: : 3it [00:32, 10.66s/it]Evaluating RM: : 4it [00:58, 16.65s/it]Evaluating RM: : 5it [01:09, 14.69s/it]Evaluating RM: : 6it [01:30, 16.79s/it]Evaluating RM: : 7it [01:46, 16.64s/it]Evaluating RM: : 8it [02:01, 16.17s/it]Evaluating RM: : 9it [02:14, 14.94s/it]Evaluating RM: : 10it [02:28, 14.70s/it]Evaluating RM: : 11it [02:47, 16.18s/it]Evaluating RM: : 12it [03:09, 17.92s/it]Evaluating RM: : 13it [03:26, 17.47s/it]Evaluating RM: : 14it [03:35, 15.18s/it]Evaluating RM: : 15it [03:49, 14.71s/it]Evaluating RM: : 16it [03:59, 13.40s/it]Evaluating RM: : 17it [04:10, 12.65s/it]Evaluating RM: : 18it [04:23, 12.79s/it]Evaluating RM: : 19it [04:33, 11.81s/it]Evaluating RM: : 20it [04:58, 15.92s/it]Evaluating RM: : 21it [05:10, 14.58s/it]2024-05-30 21:59:41 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 21
Evaluating RM: : 22it [05:36, 18.03s/it]Evaluating RM: : 23it [06:04, 20.94s/it]Evaluating RM: : 24it [06:25, 20.98s/it]2024-05-30 22:00:52 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 24
Evaluating RM: : 25it [06:47, 21.38s/it]Evaluating RM: : 26it [07:14, 23.16s/it]Evaluating RM: : 27it [07:34, 22.19s/it]Evaluating RM: : 28it [07:48, 19.55s/it]2024-05-30 22:02:15 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 28
Evaluating RM: : 29it [08:10, 20.21s/it]Evaluating RM: : 30it [08:22, 17.94s/it]Evaluating RM: : 31it [08:33, 15.81s/it]Evaluating RM: : 32it [08:50, 16.30s/it]Evaluating RM: : 33it [09:02, 14.78s/it]2024-05-30 22:03:23 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 33
Evaluating RM: : 34it [09:18, 15.36s/it]Evaluating RM: : 35it [09:33, 15.01s/it]Evaluating RM: : 36it [09:42, 13.29s/it]Evaluating RM: : 37it [09:54, 12.92s/it]Evaluating RM: : 38it [10:09, 13.64s/it]Evaluating RM: : 39it [10:24, 13.97s/it]Evaluating RM: : 40it [10:34, 12.93s/it]Evaluating RM: : 41it [10:42, 11.26s/it]Evaluating RM: : 42it [10:55, 11.85s/it]Evaluating RM: : 43it [11:04, 11.12s/it]Evaluating RM: : 44it [11:27, 14.58s/it]Evaluating RM: : 45it [11:46, 15.72s/it]Evaluating RM: : 46it [12:01, 15.68s/it]2024-05-30 22:06:29 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 46
Evaluating RM: : 47it [12:24, 17.76s/it]Evaluating RM: : 48it [12:34, 15.62s/it]Evaluating RM: : 49it [12:42, 13.18s/it]Evaluating RM: : 50it [12:54, 12.90s/it]Evaluating RM: : 51it [13:07, 12.98s/it]Evaluating RM: : 52it [13:21, 13.35s/it]2024-05-30 22:07:52 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 52
Evaluating RM: : 53it [13:47, 16.90s/it]Evaluating RM: : 54it [14:10, 18.84s/it]Evaluating RM: : 55it [14:15, 14.73s/it]Evaluating RM: : 56it [14:43, 18.71s/it]Evaluating RM: : 56it [14:43, 15.78s/it]
2024-05-30 22:08:48 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
