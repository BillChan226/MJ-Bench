2024-05-30 21:07:29 | INFO | alignment_rm_score | Loading reward model form llava-1.5-7b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.44it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.67it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:07:37 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_narrative_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:09,  9.97s/it]Evaluating RM: : 2it [00:16,  8.16s/it]Evaluating RM: : 3it [00:22,  6.92s/it]Evaluating RM: : 4it [00:32,  8.21s/it]Evaluating RM: : 5it [00:39,  7.71s/it]Evaluating RM: : 6it [00:48,  8.11s/it]Evaluating RM: : 7it [00:55,  7.81s/it]Evaluating RM: : 8it [01:01,  7.32s/it]Evaluating RM: : 9it [01:08,  7.30s/it]Evaluating RM: : 10it [01:17,  7.58s/it]Evaluating RM: : 11it [01:24,  7.57s/it]Evaluating RM: : 12it [01:30,  7.06s/it]Evaluating RM: : 13it [01:37,  6.98s/it]Evaluating RM: : 14it [01:43,  6.73s/it]Evaluating RM: : 15it [01:50,  6.80s/it]Evaluating RM: : 16it [01:57,  6.77s/it]Evaluating RM: : 17it [02:03,  6.68s/it]Evaluating RM: : 18it [02:11,  6.90s/it]Evaluating RM: : 19it [02:18,  7.02s/it]Evaluating RM: : 20it [02:25,  7.03s/it]Evaluating RM: : 21it [02:33,  7.21s/it]Evaluating RM: : 22it [02:42,  7.91s/it]Evaluating RM: : 23it [02:51,  8.16s/it]Evaluating RM: : 24it [03:01,  8.70s/it]Evaluating RM: : 25it [03:12,  9.31s/it]Evaluating RM: : 26it [03:19,  8.72s/it]Evaluating RM: : 27it [03:29,  9.21s/it]Evaluating RM: : 28it [03:39,  9.52s/it]Evaluating RM: : 29it [03:50,  9.74s/it]Evaluating RM: : 30it [03:56,  8.85s/it]Evaluating RM: : 31it [04:04,  8.55s/it]Evaluating RM: : 32it [04:11,  8.01s/it]Evaluating RM: : 33it [04:19,  7.85s/it]Evaluating RM: : 34it [04:26,  7.58s/it]Evaluating RM: : 35it [04:31,  7.08s/it]Evaluating RM: : 36it [04:36,  6.34s/it]Evaluating RM: : 37it [04:43,  6.59s/it]Evaluating RM: : 38it [04:50,  6.76s/it]Evaluating RM: : 39it [04:56,  6.51s/it]Evaluating RM: : 40it [05:04,  6.82s/it]Evaluating RM: : 41it [05:12,  7.08s/it]Evaluating RM: : 42it [05:18,  6.85s/it]Evaluating RM: : 43it [05:24,  6.57s/it]Evaluating RM: : 44it [05:30,  6.57s/it]Evaluating RM: : 45it [05:38,  6.94s/it]Evaluating RM: : 46it [05:43,  6.44s/it]Evaluating RM: : 47it [05:51,  6.71s/it]Evaluating RM: : 48it [05:58,  6.74s/it]Evaluating RM: : 49it [06:05,  7.01s/it]Evaluating RM: : 50it [06:13,  7.18s/it]Evaluating RM: : 51it [06:19,  6.81s/it]Evaluating RM: : 52it [06:26,  6.86s/it]Evaluating RM: : 53it [06:34,  7.35s/it]Evaluating RM: : 54it [06:41,  7.33s/it]Evaluating RM: : 55it [06:50,  7.54s/it]Evaluating RM: : 56it [06:57,  7.45s/it]Evaluating RM: : 56it [06:57,  7.45s/it]
2024-05-30 21:14:34 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
