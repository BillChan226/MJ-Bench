2024-05-30 21:56:36 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 21:56:39 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.02it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.06it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.09it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.10it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.11it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 21:56:45 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:16, 16.63s/it]Evaluating RM: : 2it [00:27, 13.00s/it]Evaluating RM: : 3it [00:43, 14.61s/it]Evaluating RM: : 4it [01:08, 18.58s/it]Evaluating RM: : 5it [01:20, 16.44s/it]Evaluating RM: : 6it [01:39, 17.08s/it]Evaluating RM: : 7it [01:51, 15.45s/it]Evaluating RM: : 8it [02:07, 15.53s/it]Evaluating RM: : 9it [02:22, 15.59s/it]Evaluating RM: : 10it [02:39, 15.87s/it]Evaluating RM: : 11it [02:55, 16.09s/it]Evaluating RM: : 12it [03:08, 14.95s/it]Evaluating RM: : 13it [03:18, 13.49s/it]Evaluating RM: : 14it [03:38, 15.43s/it]2024-05-30 22:00:47 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 14
Evaluating RM: : 15it [04:02, 17.96s/it]Evaluating RM: : 16it [04:14, 16.23s/it]Evaluating RM: : 17it [04:26, 14.91s/it]Evaluating RM: : 18it [04:39, 14.46s/it]Evaluating RM: : 19it [04:50, 13.35s/it]Evaluating RM: : 20it [05:13, 16.33s/it]Evaluating RM: : 21it [05:26, 15.25s/it]Evaluating RM: : 22it [05:38, 14.36s/it]Evaluating RM: : 23it [06:00, 16.51s/it]Evaluating RM: : 24it [06:18, 17.01s/it]Evaluating RM: : 25it [06:47, 20.55s/it]Evaluating RM: : 26it [07:02, 18.98s/it]Evaluating RM: : 27it [07:33, 22.57s/it]Evaluating RM: : 28it [07:42, 18.58s/it]2024-05-30 22:04:49 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 28
Evaluating RM: : 29it [08:04, 19.51s/it]Evaluating RM: : 30it [08:16, 17.39s/it]Evaluating RM: : 31it [08:25, 14.78s/it]Evaluating RM: : 32it [08:39, 14.63s/it]Evaluating RM: : 33it [08:57, 15.59s/it]Evaluating RM: : 34it [09:16, 16.64s/it]Evaluating RM: : 35it [09:30, 15.76s/it]Evaluating RM: : 36it [09:39, 13.86s/it]Evaluating RM: : 37it [09:49, 12.65s/it]Evaluating RM: : 38it [10:05, 13.73s/it]Evaluating RM: : 39it [10:24, 15.30s/it]Evaluating RM: : 40it [10:34, 13.72s/it]Evaluating RM: : 41it [10:45, 12.67s/it]Evaluating RM: : 42it [10:56, 12.35s/it]Evaluating RM: : 43it [11:06, 11.50s/it]Evaluating RM: : 44it [11:26, 14.14s/it]Evaluating RM: : 45it [11:41, 14.44s/it]Evaluating RM: : 46it [11:59, 15.37s/it]Evaluating RM: : 47it [12:18, 16.52s/it]Evaluating RM: : 48it [12:34, 16.30s/it]Evaluating RM: : 49it [12:41, 13.72s/it]Evaluating RM: : 50it [12:54, 13.29s/it]Evaluating RM: : 51it [13:05, 12.76s/it]Evaluating RM: : 52it [13:20, 13.31s/it]Evaluating RM: : 53it [13:47, 17.38s/it]Evaluating RM: : 54it [14:07, 18.24s/it]Evaluating RM: : 55it [14:12, 14.34s/it]2024-05-30 22:11:15 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 55
Evaluating RM: : 56it [14:30, 15.31s/it]Evaluating RM: : 56it [14:30, 15.54s/it]
2024-05-30 22:11:15 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
