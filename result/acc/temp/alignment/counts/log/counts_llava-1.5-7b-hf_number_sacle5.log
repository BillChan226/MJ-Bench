2024-05-30 21:23:53 | INFO | alignment_rm_score | Loading reward model form llava-1.5-7b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.35it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.47it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:24:02 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:10, 10.12s/it]Evaluating RM: : 2it [00:16,  8.07s/it]Evaluating RM: : 3it [00:24,  7.70s/it]Evaluating RM: : 4it [00:35,  9.19s/it]Evaluating RM: : 5it [00:41,  8.18s/it]Evaluating RM: : 6it [00:50,  8.24s/it]Evaluating RM: : 7it [00:58,  8.37s/it]Evaluating RM: : 8it [01:04,  7.50s/it]Evaluating RM: : 9it [01:12,  7.51s/it]Evaluating RM: : 10it [01:20,  7.76s/it]Evaluating RM: : 11it [01:29,  8.03s/it]Evaluating RM: : 12it [01:35,  7.63s/it]2024-05-30 21:25:45 | INFO | alignment_rm_score | Cannot parsing the score from vlm output. sample id is 12
Evaluating RM: : 13it [01:43,  7.72s/it]Evaluating RM: : 14it [01:52,  8.00s/it]Evaluating RM: : 15it [01:58,  7.50s/it]Evaluating RM: : 16it [02:04,  7.11s/it]Evaluating RM: : 17it [02:09,  6.24s/it]Evaluating RM: : 18it [02:16,  6.71s/it]Evaluating RM: : 19it [02:24,  6.96s/it]Evaluating RM: : 20it [02:31,  7.02s/it]Evaluating RM: : 21it [02:37,  6.67s/it]Evaluating RM: : 22it [02:44,  6.86s/it]Evaluating RM: : 23it [02:52,  7.09s/it]Evaluating RM: : 24it [03:04,  8.52s/it]Evaluating RM: : 25it [03:13,  8.83s/it]Evaluating RM: : 26it [03:19,  8.05s/it]Evaluating RM: : 27it [03:30,  8.80s/it]Evaluating RM: : 28it [03:41,  9.45s/it]Evaluating RM: : 29it [03:51,  9.46s/it]Evaluating RM: : 30it [03:57,  8.55s/it]Evaluating RM: : 31it [04:06,  8.60s/it]Evaluating RM: : 32it [04:13,  8.24s/it]Evaluating RM: : 33it [04:20,  7.90s/it]Evaluating RM: : 34it [04:26,  7.15s/it]Evaluating RM: : 35it [04:32,  6.81s/it]Evaluating RM: : 36it [04:37,  6.50s/it]Evaluating RM: : 37it [04:45,  6.99s/it]Evaluating RM: : 38it [04:53,  7.04s/it]Evaluating RM: : 39it [04:59,  6.77s/it]Evaluating RM: : 40it [05:07,  7.14s/it]Evaluating RM: : 41it [05:13,  6.82s/it]Evaluating RM: : 42it [05:19,  6.75s/it]Evaluating RM: : 43it [05:26,  6.63s/it]Evaluating RM: : 44it [05:33,  6.79s/it]Evaluating RM: : 45it [05:41,  7.05s/it]Evaluating RM: : 46it [05:46,  6.54s/it]Evaluating RM: : 47it [05:57,  7.93s/it]Evaluating RM: : 48it [06:04,  7.68s/it]Evaluating RM: : 49it [06:10,  7.20s/it]Evaluating RM: : 50it [06:17,  7.13s/it]Evaluating RM: : 51it [06:23,  6.74s/it]Evaluating RM: : 52it [06:30,  6.84s/it]Evaluating RM: : 53it [06:40,  7.73s/it]Evaluating RM: : 54it [06:47,  7.57s/it]Evaluating RM: : 55it [06:52,  6.69s/it]Evaluating RM: : 56it [07:00,  7.23s/it]Evaluating RM: : 56it [07:00,  7.51s/it]
2024-05-30 21:31:03 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
