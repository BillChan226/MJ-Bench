2024-05-30 21:06:05 | INFO | alignment_rm_score | Loading reward model form llava-1.5-13b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.46it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.63it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  1.73it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.83it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:02<00:00,  1.89it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  2.27it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:06:18 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/alignment_single_narrative_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:12, 12.69s/it]Evaluating RM: : 2it [00:25, 12.53s/it]Evaluating RM: : 3it [00:36, 12.16s/it]Evaluating RM: : 4it [00:51, 13.08s/it]Evaluating RM: : 5it [01:05, 13.34s/it]Evaluating RM: : 6it [01:19, 13.59s/it]Evaluating RM: : 7it [01:30, 12.97s/it]Evaluating RM: : 8it [01:41, 12.08s/it]Evaluating RM: : 9it [01:53, 12.17s/it]Evaluating RM: : 10it [02:06, 12.31s/it]Evaluating RM: : 11it [02:19, 12.60s/it]Evaluating RM: : 12it [02:32, 12.77s/it]Evaluating RM: : 13it [02:43, 12.32s/it]Evaluating RM: : 14it [02:55, 12.15s/it]Evaluating RM: : 15it [03:08, 12.36s/it]Evaluating RM: : 16it [03:19, 11.95s/it]Evaluating RM: : 17it [03:30, 11.79s/it]Evaluating RM: : 18it [03:42, 11.74s/it]Evaluating RM: : 19it [03:55, 12.10s/it]Evaluating RM: : 20it [04:06, 11.97s/it]Evaluating RM: : 21it [04:19, 12.05s/it]Evaluating RM: : 22it [04:33, 12.58s/it]Evaluating RM: : 23it [04:45, 12.58s/it]Evaluating RM: : 24it [05:05, 14.81s/it]Evaluating RM: : 25it [05:18, 14.14s/it]Evaluating RM: : 26it [05:30, 13.46s/it]Evaluating RM: : 27it [05:44, 13.77s/it]Evaluating RM: : 28it [05:59, 14.18s/it]Evaluating RM: : 29it [06:13, 14.20s/it]Evaluating RM: : 30it [06:24, 13.13s/it]Evaluating RM: : 31it [06:36, 12.82s/it]Evaluating RM: : 32it [06:51, 13.33s/it]Evaluating RM: : 33it [07:02, 12.78s/it]Evaluating RM: : 34it [07:14, 12.58s/it]Evaluating RM: : 35it [07:25, 12.10s/it]Evaluating RM: : 36it [07:37, 11.98s/it]Evaluating RM: : 37it [07:48, 11.59s/it]Evaluating RM: : 38it [07:58, 11.30s/it]Evaluating RM: : 39it [08:12, 11.92s/it]Evaluating RM: : 40it [08:24, 11.96s/it]Evaluating RM: : 41it [08:34, 11.48s/it]Evaluating RM: : 42it [08:49, 12.44s/it]Evaluating RM: : 43it [08:59, 11.92s/it]Evaluating RM: : 44it [09:13, 12.29s/it]Evaluating RM: : 45it [09:28, 13.17s/it]Evaluating RM: : 46it [09:38, 12.41s/it]Evaluating RM: : 47it [09:54, 13.21s/it]Evaluating RM: : 48it [10:06, 13.06s/it]Evaluating RM: : 49it [10:17, 12.23s/it]Evaluating RM: : 50it [10:29, 12.37s/it]Evaluating RM: : 51it [10:41, 12.05s/it]Evaluating RM: : 52it [10:55, 12.81s/it]Evaluating RM: : 53it [11:10, 13.29s/it]Evaluating RM: : 54it [11:25, 13.80s/it]Evaluating RM: : 55it [11:38, 13.58s/it]Evaluating RM: : 56it [11:51, 13.63s/it]Evaluating RM: : 56it [11:51, 12.71s/it]
2024-05-30 21:18:10 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/alignment/counts
