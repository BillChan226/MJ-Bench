2024-05-30 22:07:45 | INFO | alignment_rm_score | Loading reward model form llava-1.5-7b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.30it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.45it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 22:07:53 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/safety_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:11, 11.32s/it]Evaluating RM: : 2it [00:20, 10.23s/it]Evaluating RM: : 3it [00:27,  8.79s/it]Evaluating RM: : 4it [00:34,  7.91s/it]Evaluating RM: : 5it [00:42,  7.84s/it]Evaluating RM: : 6it [00:49,  7.63s/it]Evaluating RM: : 7it [00:57,  7.86s/it]Evaluating RM: : 8it [01:03,  7.21s/it]Evaluating RM: : 9it [01:11,  7.40s/it]Evaluating RM: : 10it [01:18,  7.26s/it]Evaluating RM: : 11it [01:25,  7.40s/it]Evaluating RM: : 12it [01:34,  7.67s/it]Evaluating RM: : 13it [01:40,  7.38s/it]Evaluating RM: : 14it [01:46,  6.81s/it]Evaluating RM: : 15it [01:53,  7.00s/it]Evaluating RM: : 16it [02:02,  7.38s/it]Evaluating RM: : 17it [02:08,  7.10s/it]Evaluating RM: : 18it [02:16,  7.26s/it]Evaluating RM: : 19it [02:23,  7.29s/it]Evaluating RM: : 20it [02:30,  7.30s/it]Evaluating RM: : 21it [02:37,  7.10s/it]Evaluating RM: : 22it [02:45,  7.47s/it]Evaluating RM: : 23it [02:51,  7.00s/it]Evaluating RM: : 24it [02:57,  6.54s/it]Evaluating RM: : 25it [03:05,  6.96s/it]Evaluating RM: : 26it [03:12,  6.96s/it]Evaluating RM: : 27it [03:20,  7.37s/it]Evaluating RM: : 28it [03:29,  7.79s/it]Evaluating RM: : 29it [03:36,  7.63s/it]Evaluating RM: : 30it [03:43,  7.49s/it]Evaluating RM: : 31it [03:49,  6.85s/it]Evaluating RM: : 32it [03:56,  6.95s/it]Evaluating RM: : 33it [04:02,  6.70s/it]Evaluating RM: : 34it [04:08,  6.68s/it]Evaluating RM: : 35it [04:17,  7.20s/it]Evaluating RM: : 36it [04:26,  7.80s/it]Evaluating RM: : 37it [04:33,  7.67s/it]Evaluating RM: : 38it [04:41,  7.56s/it]Evaluating RM: : 39it [04:46,  6.95s/it]Evaluating RM: : 40it [04:53,  7.02s/it]Evaluating RM: : 41it [05:01,  7.11s/it]Evaluating RM: : 42it [05:08,  7.12s/it]Evaluating RM: : 43it [05:15,  7.17s/it]Evaluating RM: : 44it [05:21,  6.83s/it]Evaluating RM: : 45it [05:29,  7.00s/it]Evaluating RM: : 46it [05:34,  6.59s/it]Evaluating RM: : 47it [05:41,  6.56s/it]Evaluating RM: : 48it [05:49,  7.03s/it]Evaluating RM: : 49it [05:57,  7.39s/it]Evaluating RM: : 50it [06:05,  7.64s/it]Evaluating RM: : 51it [06:13,  7.58s/it]Evaluating RM: : 52it [06:22,  7.97s/it]Evaluating RM: : 53it [06:29,  7.78s/it]Evaluating RM: : 54it [06:36,  7.51s/it]Evaluating RM: : 55it [06:43,  7.28s/it]Evaluating RM: : 56it [06:50,  7.40s/it]Evaluating RM: : 57it [06:56,  6.86s/it]Evaluating RM: : 58it [07:04,  7.36s/it]Evaluating RM: : 59it [07:11,  7.16s/it]Evaluating RM: : 60it [07:18,  7.10s/it]Evaluating RM: : 61it [07:25,  7.08s/it]Evaluating RM: : 62it [07:31,  6.67s/it]Evaluating RM: : 63it [07:38,  6.94s/it]Evaluating RM: : 64it [07:46,  7.29s/it]Evaluating RM: : 65it [07:55,  7.67s/it]Evaluating RM: : 66it [08:01,  7.24s/it]Evaluating RM: : 67it [08:09,  7.48s/it]Evaluating RM: : 68it [08:17,  7.59s/it]Evaluating RM: : 69it [08:24,  7.23s/it]Evaluating RM: : 70it [08:30,  6.87s/it]Evaluating RM: : 71it [08:35,  6.55s/it]Evaluating RM: : 72it [08:43,  6.88s/it]Evaluating RM: : 73it [08:49,  6.74s/it]Evaluating RM: : 74it [08:57,  6.90s/it]Evaluating RM: : 75it [09:03,  6.68s/it]Evaluating RM: : 76it [09:10,  6.80s/it]Evaluating RM: : 77it [09:18,  7.07s/it]Evaluating RM: : 78it [09:24,  6.92s/it]Evaluating RM: : 79it [09:31,  6.94s/it]Evaluating RM: : 80it [09:37,  6.69s/it]Evaluating RM: : 81it [09:45,  6.95s/it]Evaluating RM: : 82it [09:53,  7.44s/it]Evaluating RM: : 83it [09:59,  6.90s/it]Evaluating RM: : 84it [10:06,  6.97s/it]Evaluating RM: : 85it [10:13,  7.03s/it]Evaluating RM: : 86it [10:19,  6.63s/it]Evaluating RM: : 87it [10:26,  6.83s/it]Evaluating RM: : 88it [10:33,  6.65s/it]Evaluating RM: : 89it [10:41,  7.14s/it]Evaluating RM: : 90it [10:48,  7.19s/it]Evaluating RM: : 90it [10:48,  7.21s/it]
2024-05-30 22:18:42 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/safety/toxic
