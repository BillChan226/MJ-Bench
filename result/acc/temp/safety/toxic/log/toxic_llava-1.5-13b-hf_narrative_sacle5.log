2024-05-30 22:22:19 | INFO | alignment_rm_score | Loading reward model form llava-1.5-13b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.30it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.40it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.43it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.46it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.55it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 22:22:31 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/safety_single_narrative_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:13, 13.99s/it]Evaluating RM: : 2it [00:27, 13.82s/it]Evaluating RM: : 3it [00:39, 12.77s/it]Evaluating RM: : 4it [00:49, 11.73s/it]Evaluating RM: : 5it [01:03, 12.55s/it]Evaluating RM: : 6it [01:15, 12.29s/it]Evaluating RM: : 7it [01:26, 11.91s/it]Evaluating RM: : 8it [01:35, 11.05s/it]Evaluating RM: : 9it [01:47, 11.20s/it]Evaluating RM: : 10it [01:59, 11.56s/it]Evaluating RM: : 11it [02:12, 12.06s/it]Evaluating RM: : 12it [02:24, 12.07s/it]Evaluating RM: : 13it [02:36, 12.06s/it]Evaluating RM: : 14it [02:46, 11.51s/it]Evaluating RM: : 15it [03:00, 12.19s/it]Evaluating RM: : 16it [03:13, 12.23s/it]Evaluating RM: : 17it [03:22, 11.54s/it]Evaluating RM: : 18it [03:35, 11.91s/it]Evaluating RM: : 19it [03:49, 12.52s/it]Evaluating RM: : 20it [03:59, 11.81s/it]Evaluating RM: : 21it [04:10, 11.59s/it]Evaluating RM: : 22it [04:25, 12.44s/it]Evaluating RM: : 23it [04:36, 12.15s/it]Evaluating RM: : 24it [04:45, 11.19s/it]Evaluating RM: : 25it [04:56, 10.94s/it]Evaluating RM: : 26it [05:09, 11.71s/it]Evaluating RM: : 27it [05:21, 11.78s/it]Evaluating RM: : 28it [05:35, 12.35s/it]Evaluating RM: : 29it [05:46, 12.12s/it]Evaluating RM: : 30it [05:59, 12.44s/it]Evaluating RM: : 31it [06:12, 12.56s/it]Evaluating RM: : 32it [06:25, 12.51s/it]Evaluating RM: : 33it [06:38, 12.80s/it]Evaluating RM: : 34it [06:49, 12.12s/it]Evaluating RM: : 35it [07:01, 12.14s/it]Evaluating RM: : 36it [07:14, 12.31s/it]Evaluating RM: : 37it [07:23, 11.56s/it]Evaluating RM: : 38it [07:35, 11.47s/it]Evaluating RM: : 39it [07:45, 11.04s/it]Evaluating RM: : 40it [07:57, 11.38s/it]Evaluating RM: : 41it [08:07, 11.11s/it]Evaluating RM: : 42it [08:20, 11.47s/it]Evaluating RM: : 43it [08:31, 11.57s/it]Evaluating RM: : 44it [08:44, 11.86s/it]Evaluating RM: : 45it [08:57, 12.20s/it]Evaluating RM: : 46it [09:09, 11.98s/it]Evaluating RM: : 47it [09:22, 12.36s/it]Evaluating RM: : 48it [09:34, 12.41s/it]Evaluating RM: : 49it [09:47, 12.38s/it]Evaluating RM: : 50it [09:58, 12.23s/it]Evaluating RM: : 51it [10:11, 12.24s/it]Evaluating RM: : 52it [10:25, 12.93s/it]Evaluating RM: : 53it [10:37, 12.62s/it]Evaluating RM: : 54it [10:47, 11.74s/it]Evaluating RM: : 55it [10:59, 11.96s/it]Evaluating RM: : 56it [11:12, 12.24s/it]Evaluating RM: : 57it [11:22, 11.55s/it]Evaluating RM: : 58it [11:33, 11.42s/it]Evaluating RM: : 59it [11:45, 11.46s/it]Evaluating RM: : 60it [11:59, 12.14s/it]Evaluating RM: : 61it [12:11, 12.21s/it]Evaluating RM: : 62it [12:24, 12.59s/it]Evaluating RM: : 63it [12:36, 12.17s/it]Evaluating RM: : 64it [12:50, 12.77s/it]Evaluating RM: : 65it [13:04, 13.14s/it]Evaluating RM: : 66it [13:15, 12.66s/it]Evaluating RM: : 67it [13:28, 12.69s/it]Evaluating RM: : 68it [13:41, 12.86s/it]Evaluating RM: : 69it [13:52, 12.18s/it]Evaluating RM: : 70it [14:03, 11.81s/it]Evaluating RM: : 71it [14:14, 11.58s/it]Evaluating RM: : 72it [14:27, 12.16s/it]Evaluating RM: : 73it [14:39, 12.13s/it]Evaluating RM: : 74it [14:51, 11.93s/it]Evaluating RM: : 75it [15:01, 11.30s/it]Evaluating RM: : 76it [15:13, 11.60s/it]Evaluating RM: : 77it [15:25, 11.61s/it]Evaluating RM: : 78it [15:37, 11.68s/it]Evaluating RM: : 79it [15:47, 11.21s/it]Evaluating RM: : 80it [15:57, 10.94s/it]Evaluating RM: : 81it [16:10, 11.49s/it]Evaluating RM: : 82it [16:22, 11.59s/it]Evaluating RM: : 83it [16:32, 11.14s/it]Evaluating RM: : 84it [16:44, 11.47s/it]Evaluating RM: : 85it [16:56, 11.60s/it]Evaluating RM: : 86it [17:05, 10.95s/it]Evaluating RM: : 87it [17:17, 11.26s/it]Evaluating RM: : 88it [17:29, 11.30s/it]Evaluating RM: : 89it [17:41, 11.64s/it]Evaluating RM: : 90it [17:54, 12.09s/it]Evaluating RM: : 90it [17:54, 11.94s/it]
2024-05-30 22:40:26 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/safety/toxic
