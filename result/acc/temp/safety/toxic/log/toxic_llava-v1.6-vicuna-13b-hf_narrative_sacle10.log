2024-05-30 23:05:43 | INFO | alignment_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 23:05:46 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.05s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.02s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.02s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.03s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 23:05:52 | INFO | alignment_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/safety_single_narrative_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:13, 13.47s/it]Evaluating RM: : 2it [00:28, 14.67s/it]Evaluating RM: : 3it [00:35, 11.12s/it]Evaluating RM: : 4it [00:43,  9.82s/it]Evaluating RM: : 5it [00:56, 11.02s/it]Evaluating RM: : 6it [01:07, 10.83s/it]Evaluating RM: : 7it [01:15, 10.12s/it]Evaluating RM: : 8it [01:24,  9.67s/it]Evaluating RM: : 9it [01:33,  9.28s/it]Evaluating RM: : 10it [01:42,  9.35s/it]Evaluating RM: : 11it [01:58, 11.31s/it]Evaluating RM: : 12it [02:13, 12.61s/it]Evaluating RM: : 13it [02:23, 11.81s/it]Evaluating RM: : 14it [02:33, 11.22s/it]Evaluating RM: : 15it [02:44, 11.05s/it]Evaluating RM: : 16it [02:54, 10.79s/it]Evaluating RM: : 17it [03:03, 10.17s/it]Evaluating RM: : 18it [03:12,  9.89s/it]Evaluating RM: : 19it [03:20,  9.42s/it]Evaluating RM: : 20it [03:32, 10.14s/it]Evaluating RM: : 21it [03:42, 10.01s/it]Evaluating RM: : 22it [03:52, 10.13s/it]Evaluating RM: : 23it [04:02,  9.86s/it]Evaluating RM: : 24it [04:09,  9.28s/it]Evaluating RM: : 25it [04:19,  9.40s/it]Evaluating RM: : 26it [04:29,  9.52s/it]Evaluating RM: : 27it [04:41, 10.37s/it]Evaluating RM: : 28it [04:52, 10.36s/it]Evaluating RM: : 29it [05:07, 11.82s/it]Evaluating RM: : 30it [05:18, 11.62s/it]Evaluating RM: : 31it [05:30, 11.58s/it]Evaluating RM: : 32it [05:47, 13.31s/it]Evaluating RM: : 33it [05:56, 12.02s/it]Evaluating RM: : 34it [06:04, 10.79s/it]Evaluating RM: : 35it [06:13, 10.40s/it]Evaluating RM: : 36it [06:24, 10.44s/it]Evaluating RM: : 37it [06:33, 10.06s/it]Evaluating RM: : 38it [06:43, 10.17s/it]Evaluating RM: : 39it [06:56, 10.92s/it]Evaluating RM: : 40it [07:07, 10.83s/it]Evaluating RM: : 41it [07:21, 11.83s/it]Evaluating RM: : 42it [07:30, 11.03s/it]Evaluating RM: : 43it [07:41, 11.11s/it]Evaluating RM: : 44it [07:54, 11.65s/it]Evaluating RM: : 45it [08:07, 11.83s/it]Evaluating RM: : 46it [08:15, 10.88s/it]Evaluating RM: : 47it [08:26, 10.89s/it]Evaluating RM: : 48it [08:36, 10.69s/it]Evaluating RM: : 49it [08:46, 10.50s/it]Evaluating RM: : 50it [08:57, 10.42s/it]Evaluating RM: : 51it [09:04,  9.65s/it]Evaluating RM: : 52it [09:17, 10.43s/it]Evaluating RM: : 53it [09:28, 10.75s/it]Evaluating RM: : 54it [09:37, 10.22s/it]Evaluating RM: : 55it [09:52, 11.57s/it]Evaluating RM: : 56it [10:02, 11.27s/it]Evaluating RM: : 57it [10:13, 11.00s/it]Evaluating RM: : 58it [10:21, 10.11s/it]Evaluating RM: : 59it [10:34, 11.16s/it]Evaluating RM: : 60it [10:46, 11.28s/it]Evaluating RM: : 61it [10:55, 10.65s/it]Evaluating RM: : 62it [11:06, 10.65s/it]Evaluating RM: : 63it [11:18, 10.95s/it]Evaluating RM: : 64it [11:31, 11.59s/it]Evaluating RM: : 65it [11:39, 10.75s/it]Evaluating RM: : 66it [11:51, 11.11s/it]Evaluating RM: : 67it [12:03, 11.16s/it]Evaluating RM: : 68it [12:18, 12.41s/it]Evaluating RM: : 69it [12:26, 11.02s/it]Evaluating RM: : 70it [12:34, 10.13s/it]Evaluating RM: : 71it [12:44, 10.08s/it]Evaluating RM: : 72it [12:57, 11.14s/it]Evaluating RM: : 73it [13:05, 10.21s/it]Evaluating RM: : 74it [13:13,  9.48s/it]Evaluating RM: : 75it [13:24,  9.87s/it]Evaluating RM: : 76it [13:32,  9.42s/it]Evaluating RM: : 77it [13:43,  9.92s/it]Evaluating RM: : 78it [13:58, 11.31s/it]Evaluating RM: : 79it [14:09, 11.16s/it]Evaluating RM: : 80it [14:19, 10.82s/it]Evaluating RM: : 81it [14:29, 10.54s/it]Evaluating RM: : 82it [14:40, 10.71s/it]Evaluating RM: : 83it [14:48, 10.05s/it]Evaluating RM: : 84it [15:00, 10.52s/it]Evaluating RM: : 85it [15:12, 11.04s/it]Evaluating RM: : 86it [15:23, 10.83s/it]Evaluating RM: : 87it [15:32, 10.38s/it]Evaluating RM: : 88it [15:41,  9.96s/it]Evaluating RM: : 89it [15:50,  9.71s/it]Evaluating RM: : 90it [16:06, 11.69s/it]Evaluating RM: : 90it [16:06, 10.74s/it]
2024-05-30 23:21:59 | INFO | alignment_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/safety/toxic
