2024-05-30 21:23:13 | INFO | artifacte_rm_score | Loading reward model form llava-1.5-7b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.41it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:23:21 | INFO | artifacte_rm_score | Loading dataset from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/artifacts/objects_indoor...
2024-05-30 21:23:22 | INFO | artifacte_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/artifacts_single_narrative_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:09,  9.99s/it]Evaluating RM: : 2it [00:17,  8.49s/it]Evaluating RM: : 3it [00:25,  8.51s/it]Evaluating RM: : 4it [00:32,  7.62s/it]Evaluating RM: : 5it [00:40,  7.87s/it]Evaluating RM: : 6it [00:48,  7.79s/it]Evaluating RM: : 7it [00:56,  8.06s/it]Evaluating RM: : 8it [01:04,  7.94s/it]Evaluating RM: : 9it [01:12,  7.84s/it]Evaluating RM: : 10it [01:19,  7.82s/it]Evaluating RM: : 11it [01:28,  7.95s/it]Evaluating RM: : 12it [01:36,  8.01s/it]Evaluating RM: : 13it [01:43,  7.65s/it]Evaluating RM: : 14it [01:51,  7.77s/it]Evaluating RM: : 15it [01:59,  8.07s/it]Evaluating RM: : 16it [02:07,  8.06s/it]Evaluating RM: : 17it [02:15,  7.96s/it]Evaluating RM: : 18it [02:24,  8.19s/it]Evaluating RM: : 19it [02:31,  7.76s/it]Evaluating RM: : 20it [02:40,  8.10s/it]Evaluating RM: : 21it [02:46,  7.69s/it]Evaluating RM: : 22it [02:54,  7.68s/it]Evaluating RM: : 23it [03:01,  7.46s/it]Evaluating RM: : 24it [03:11,  8.24s/it]Evaluating RM: : 25it [03:19,  8.09s/it]Evaluating RM: : 26it [03:27,  8.13s/it]Evaluating RM: : 27it [03:34,  7.88s/it]Evaluating RM: : 28it [03:41,  7.68s/it]Evaluating RM: : 29it [03:49,  7.69s/it]Evaluating RM: : 30it [03:57,  7.80s/it]Evaluating RM: : 31it [04:04,  7.65s/it]Evaluating RM: : 32it [04:13,  7.88s/it]Evaluating RM: : 33it [04:21,  8.05s/it]Evaluating RM: : 34it [04:30,  8.28s/it]Evaluating RM: : 35it [04:39,  8.34s/it]Evaluating RM: : 36it [04:46,  8.01s/it]Evaluating RM: : 37it [04:53,  7.71s/it]Evaluating RM: : 38it [05:01,  7.78s/it]Evaluating RM: : 39it [05:08,  7.57s/it]Evaluating RM: : 40it [05:15,  7.42s/it]Evaluating RM: : 41it [05:23,  7.59s/it]Evaluating RM: : 42it [05:31,  7.63s/it]Evaluating RM: : 43it [05:38,  7.60s/it]Evaluating RM: : 44it [05:46,  7.61s/it]Evaluating RM: : 45it [05:53,  7.52s/it]Evaluating RM: : 46it [06:02,  7.90s/it]Evaluating RM: : 47it [06:08,  7.41s/it]Evaluating RM: : 48it [06:16,  7.64s/it]Evaluating RM: : 49it [06:25,  7.96s/it]Evaluating RM: : 50it [06:33,  7.99s/it]Evaluating RM: : 51it [06:42,  8.10s/it]Evaluating RM: : 52it [06:50,  8.07s/it]Evaluating RM: : 53it [06:56,  7.71s/it]Evaluating RM: : 54it [07:04,  7.61s/it]Evaluating RM: : 55it [07:11,  7.50s/it]Evaluating RM: : 56it [07:19,  7.55s/it]Evaluating RM: : 57it [07:27,  7.83s/it]Evaluating RM: : 58it [07:35,  7.90s/it]Evaluating RM: : 59it [07:43,  7.92s/it]Evaluating RM: : 60it [07:52,  8.14s/it]Evaluating RM: : 61it [08:01,  8.41s/it]Evaluating RM: : 62it [08:08,  8.17s/it]Evaluating RM: : 63it [08:16,  8.03s/it]Evaluating RM: : 64it [08:24,  8.04s/it]Evaluating RM: : 65it [08:32,  8.08s/it]Evaluating RM: : 66it [08:40,  7.84s/it]Evaluating RM: : 67it [08:48,  7.91s/it]Evaluating RM: : 68it [08:57,  8.18s/it]Evaluating RM: : 69it [09:06,  8.47s/it]Evaluating RM: : 70it [09:14,  8.39s/it]Evaluating RM: : 71it [09:22,  8.32s/it]Evaluating RM: : 72it [09:29,  7.95s/it]Evaluating RM: : 73it [09:36,  7.47s/it]Evaluating RM: : 74it [09:43,  7.46s/it]Evaluating RM: : 75it [09:52,  8.06s/it]Evaluating RM: : 76it [10:00,  7.98s/it]Evaluating RM: : 77it [10:08,  7.80s/it]Evaluating RM: : 78it [10:15,  7.83s/it]Evaluating RM: : 79it [10:25,  8.44s/it]Evaluating RM: : 80it [10:33,  8.23s/it]Evaluating RM: : 81it [10:41,  8.00s/it]Evaluating RM: : 82it [10:49,  8.02s/it]Evaluating RM: : 83it [10:56,  7.78s/it]Evaluating RM: : 84it [11:04,  7.92s/it]Evaluating RM: : 85it [11:15,  8.70s/it]Evaluating RM: : 86it [11:22,  8.39s/it]Evaluating RM: : 87it [11:30,  8.23s/it]Evaluating RM: : 88it [11:39,  8.39s/it]Evaluating RM: : 89it [11:46,  8.01s/it]Evaluating RM: : 90it [11:55,  8.43s/it]Evaluating RM: : 91it [12:04,  8.60s/it]Evaluating RM: : 92it [12:11,  8.14s/it]Evaluating RM: : 93it [12:19,  8.04s/it]Evaluating RM: : 94it [12:27,  7.96s/it]Evaluating RM: : 95it [12:35,  7.89s/it]Evaluating RM: : 96it [12:44,  8.21s/it]Evaluating RM: : 97it [12:52,  8.22s/it]Evaluating RM: : 98it [12:59,  7.80s/it]Evaluating RM: : 99it [13:07,  7.90s/it]Evaluating RM: : 100it [13:17,  8.44s/it]Evaluating RM: : 100it [13:17,  7.97s/it]
2024-05-30 21:36:39 | INFO | artifacte_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/artifacts/object
