2024-05-30 21:59:14 | INFO | artifacte_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 21:59:17 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.03it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.10it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.11it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.13it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.23it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 21:59:23 | INFO | artifacte_rm_score | Loading dataset from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/artifacts/objects_indoor...
2024-05-30 21:59:23 | INFO | artifacte_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/artifacts_single_narrative_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:11, 11.01s/it]Evaluating RM: : 2it [00:20,  9.90s/it]Evaluating RM: : 3it [00:28,  9.30s/it]Evaluating RM: : 4it [00:37,  9.21s/it]Evaluating RM: : 5it [00:47,  9.30s/it]Evaluating RM: : 6it [01:02, 11.39s/it]Evaluating RM: : 7it [01:11, 10.50s/it]Evaluating RM: : 8it [01:23, 10.95s/it]Evaluating RM: : 9it [01:33, 10.70s/it]Evaluating RM: : 10it [01:42, 10.31s/it]Evaluating RM: : 11it [01:55, 11.00s/it]Evaluating RM: : 12it [02:07, 11.26s/it]Evaluating RM: : 13it [02:18, 11.20s/it]Evaluating RM: : 14it [02:27, 10.50s/it]Evaluating RM: : 15it [02:40, 11.25s/it]Evaluating RM: : 16it [02:53, 12.01s/it]Evaluating RM: : 17it [03:03, 11.17s/it]Evaluating RM: : 18it [03:15, 11.45s/it]Evaluating RM: : 19it [03:25, 11.02s/it]Evaluating RM: : 20it [03:36, 10.99s/it]Evaluating RM: : 21it [03:47, 11.15s/it]Evaluating RM: : 22it [04:00, 11.61s/it]Evaluating RM: : 23it [04:09, 10.73s/it]Evaluating RM: : 24it [04:25, 12.36s/it]Evaluating RM: : 25it [04:34, 11.50s/it]Evaluating RM: : 26it [04:45, 11.37s/it]Evaluating RM: : 27it [04:58, 11.81s/it]Evaluating RM: : 28it [05:11, 12.00s/it]Evaluating RM: : 29it [05:21, 11.61s/it]Evaluating RM: : 30it [05:32, 11.20s/it]Evaluating RM: : 31it [05:40, 10.46s/it]Evaluating RM: : 32it [05:49,  9.86s/it]Evaluating RM: : 33it [06:01, 10.45s/it]Evaluating RM: : 34it [06:12, 10.84s/it]Evaluating RM: : 35it [06:26, 11.71s/it]Evaluating RM: : 36it [06:36, 11.19s/it]Evaluating RM: : 37it [06:48, 11.33s/it]Evaluating RM: : 38it [07:03, 12.63s/it]Evaluating RM: : 39it [07:12, 11.51s/it]Evaluating RM: : 40it [07:25, 11.83s/it]Evaluating RM: : 41it [07:35, 11.46s/it]Evaluating RM: : 42it [07:47, 11.45s/it]Evaluating RM: : 43it [07:55, 10.34s/it]Evaluating RM: : 44it [08:01,  9.22s/it]Evaluating RM: : 45it [08:09,  8.87s/it]Evaluating RM: : 46it [08:18,  8.86s/it]Evaluating RM: : 47it [08:28,  9.29s/it]Evaluating RM: : 48it [08:38,  9.30s/it]Evaluating RM: : 49it [08:51, 10.49s/it]Evaluating RM: : 50it [09:01, 10.36s/it]Evaluating RM: : 51it [09:12, 10.51s/it]Evaluating RM: : 52it [09:24, 10.87s/it]Evaluating RM: : 53it [09:34, 10.87s/it]Evaluating RM: : 54it [09:50, 12.22s/it]Evaluating RM: : 55it [10:01, 11.90s/it]Evaluating RM: : 56it [10:13, 11.79s/it]Evaluating RM: : 57it [10:23, 11.30s/it]Evaluating RM: : 58it [10:35, 11.58s/it]Evaluating RM: : 59it [10:43, 10.56s/it]2024-05-30 22:10:20 | INFO | artifacte_rm_score | Cannot parsing the score from vlm output. sample id is 59
Evaluating RM: : 60it [10:57, 11.53s/it]2024-05-30 22:10:31 | INFO | artifacte_rm_score | Cannot parsing the score from vlm output. sample id is 60
Evaluating RM: : 61it [11:08, 11.28s/it]Evaluating RM: : 62it [11:20, 11.54s/it]Evaluating RM: : 63it [11:30, 11.17s/it]Evaluating RM: : 64it [11:43, 11.66s/it]Evaluating RM: : 65it [11:57, 12.28s/it]Evaluating RM: : 66it [12:07, 11.73s/it]Evaluating RM: : 67it [12:19, 11.88s/it]Evaluating RM: : 68it [12:28, 10.95s/it]Evaluating RM: : 69it [12:39, 10.90s/it]Evaluating RM: : 70it [12:49, 10.56s/it]Evaluating RM: : 71it [13:01, 10.98s/it]Evaluating RM: : 72it [13:14, 11.81s/it]Evaluating RM: : 73it [13:26, 11.78s/it]Evaluating RM: : 74it [13:40, 12.35s/it]Evaluating RM: : 75it [13:52, 12.37s/it]Evaluating RM: : 76it [14:05, 12.52s/it]Evaluating RM: : 77it [14:15, 11.64s/it]Evaluating RM: : 78it [14:26, 11.66s/it]Evaluating RM: : 79it [14:35, 10.80s/it]Evaluating RM: : 80it [14:45, 10.67s/it]Evaluating RM: : 81it [14:53,  9.85s/it]Evaluating RM: : 82it [15:05, 10.35s/it]Evaluating RM: : 83it [15:14, 10.03s/it]Evaluating RM: : 84it [15:28, 11.02s/it]Evaluating RM: : 85it [15:37, 10.51s/it]Evaluating RM: : 86it [15:53, 12.06s/it]Evaluating RM: : 87it [16:03, 11.74s/it]Evaluating RM: : 88it [16:14, 11.36s/it]Evaluating RM: : 89it [16:27, 11.84s/it]Evaluating RM: : 90it [16:38, 11.54s/it]Evaluating RM: : 91it [16:51, 12.03s/it]Evaluating RM: : 92it [17:00, 11.17s/it]Evaluating RM: : 93it [17:08, 10.07s/it]Evaluating RM: : 94it [17:18, 10.12s/it]Evaluating RM: : 95it [17:32, 11.45s/it]Evaluating RM: : 96it [17:43, 11.08s/it]Evaluating RM: : 97it [17:55, 11.39s/it]Evaluating RM: : 98it [18:05, 11.06s/it]Evaluating RM: : 99it [18:15, 10.87s/it]Evaluating RM: : 100it [18:26, 10.75s/it]Evaluating RM: : 100it [18:26, 11.06s/it]
2024-05-30 22:17:49 | INFO | artifacte_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/artifacts/object
