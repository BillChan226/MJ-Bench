2024-05-30 21:17:59 | INFO | artifacte_rm_score | Loading reward model form llava-1.5-13b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.48it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.58it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  1.69it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.75it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:02<00:00,  1.79it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  2.14it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 21:18:11 | INFO | artifacte_rm_score | Loading dataset from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/artifacts/objects_indoor...
2024-05-30 21:18:11 | INFO | artifacte_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/artifacts_single_narrative_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:13, 13.48s/it]Evaluating RM: : 2it [00:25, 12.42s/it]Evaluating RM: : 3it [00:36, 12.10s/it]Evaluating RM: : 4it [00:48, 11.88s/it]Evaluating RM: : 5it [01:04, 13.36s/it]Evaluating RM: : 6it [01:16, 12.99s/it]Evaluating RM: : 7it [01:29, 12.90s/it]Evaluating RM: : 8it [01:43, 13.42s/it]Evaluating RM: : 9it [01:56, 13.05s/it]Evaluating RM: : 10it [02:11, 13.73s/it]Evaluating RM: : 11it [02:25, 13.71s/it]Evaluating RM: : 12it [02:38, 13.75s/it]Evaluating RM: : 13it [02:49, 12.80s/it]Evaluating RM: : 14it [03:02, 12.70s/it]Evaluating RM: : 15it [03:15, 13.02s/it]Evaluating RM: : 16it [03:30, 13.66s/it]Evaluating RM: : 17it [03:42, 13.16s/it]Evaluating RM: : 18it [03:54, 12.65s/it]Evaluating RM: : 19it [04:06, 12.52s/it]Evaluating RM: : 20it [04:20, 12.97s/it]Evaluating RM: : 21it [04:31, 12.38s/it]Evaluating RM: : 22it [04:44, 12.53s/it]Evaluating RM: : 23it [04:58, 12.98s/it]Evaluating RM: : 24it [05:12, 13.37s/it]Evaluating RM: : 25it [05:25, 13.04s/it]Evaluating RM: : 26it [05:37, 13.00s/it]Evaluating RM: : 27it [05:49, 12.63s/it]Evaluating RM: : 28it [06:03, 12.99s/it]Evaluating RM: : 29it [06:15, 12.79s/it]Evaluating RM: : 30it [06:28, 12.81s/it]Evaluating RM: : 31it [06:44, 13.65s/it]Evaluating RM: : 32it [06:56, 13.06s/it]Evaluating RM: : 33it [07:11, 13.79s/it]Evaluating RM: : 34it [07:24, 13.52s/it]Evaluating RM: : 35it [07:39, 14.05s/it]Evaluating RM: : 36it [07:51, 13.28s/it]Evaluating RM: : 37it [08:05, 13.56s/it]Evaluating RM: : 38it [08:16, 12.78s/it]Evaluating RM: : 39it [08:28, 12.58s/it]Evaluating RM: : 40it [08:40, 12.50s/it]Evaluating RM: : 41it [08:52, 12.30s/it]Evaluating RM: : 42it [09:05, 12.61s/it]Evaluating RM: : 43it [09:20, 13.17s/it]Evaluating RM: : 44it [09:33, 13.13s/it]Evaluating RM: : 45it [09:45, 12.82s/it]Evaluating RM: : 46it [09:59, 13.24s/it]Evaluating RM: : 47it [10:11, 12.81s/it]Evaluating RM: : 48it [10:25, 12.98s/it]Evaluating RM: : 49it [10:39, 13.53s/it]Evaluating RM: : 50it [10:53, 13.50s/it]Evaluating RM: : 51it [11:05, 13.06s/it]Evaluating RM: : 52it [11:19, 13.40s/it]Evaluating RM: : 53it [11:32, 13.38s/it]Evaluating RM: : 54it [11:46, 13.56s/it]Evaluating RM: : 55it [11:59, 13.42s/it]Evaluating RM: : 56it [12:12, 13.07s/it]Evaluating RM: : 57it [12:26, 13.60s/it]Evaluating RM: : 58it [12:39, 13.13s/it]Evaluating RM: : 59it [12:53, 13.66s/it]Evaluating RM: : 60it [13:08, 13.86s/it]Evaluating RM: : 61it [13:21, 13.62s/it]Evaluating RM: : 62it [13:36, 14.13s/it]Evaluating RM: : 63it [13:48, 13.38s/it]Evaluating RM: : 64it [13:59, 12.77s/it]Evaluating RM: : 65it [14:13, 12.97s/it]Evaluating RM: : 66it [14:26, 13.09s/it]Evaluating RM: : 67it [14:38, 12.92s/it]Evaluating RM: : 68it [14:51, 12.78s/it]Evaluating RM: : 69it [15:06, 13.62s/it]Evaluating RM: : 70it [15:21, 13.83s/it]Evaluating RM: : 71it [15:35, 13.81s/it]Evaluating RM: : 72it [15:45, 12.84s/it]Evaluating RM: : 73it [15:59, 13.19s/it]Evaluating RM: : 74it [16:12, 13.09s/it]Evaluating RM: : 75it [16:26, 13.24s/it]Evaluating RM: : 76it [16:40, 13.56s/it]Evaluating RM: : 77it [16:51, 12.93s/it]Evaluating RM: : 78it [17:02, 12.24s/it]Evaluating RM: : 79it [17:15, 12.35s/it]Evaluating RM: : 80it [17:27, 12.32s/it]Evaluating RM: : 81it [17:39, 12.13s/it]Evaluating RM: : 82it [17:51, 12.25s/it]Evaluating RM: : 83it [18:04, 12.41s/it]Evaluating RM: : 84it [18:17, 12.58s/it]Evaluating RM: : 85it [18:31, 13.01s/it]Evaluating RM: : 86it [18:43, 12.82s/it]Evaluating RM: : 87it [18:56, 12.82s/it]Evaluating RM: : 88it [19:10, 13.25s/it]Evaluating RM: : 89it [19:24, 13.39s/it]Evaluating RM: : 90it [19:39, 13.87s/it]Evaluating RM: : 91it [19:51, 13.46s/it]Evaluating RM: : 92it [20:04, 13.07s/it]Evaluating RM: : 93it [20:16, 12.77s/it]Evaluating RM: : 94it [20:29, 13.01s/it]Evaluating RM: : 95it [20:41, 12.57s/it]Evaluating RM: : 96it [20:54, 12.69s/it]Evaluating RM: : 97it [21:05, 12.27s/it]Evaluating RM: : 98it [21:16, 11.79s/it]Evaluating RM: : 99it [21:27, 11.76s/it]Evaluating RM: : 100it [21:39, 11.74s/it]Evaluating RM: : 100it [21:39, 13.00s/it]
2024-05-30 21:39:50 | INFO | artifacte_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/artifacts/object
