2024-05-30 21:05:06 | INFO | artifacte_rm_score | Loading reward model form llava-v1.6-vicuna-13b-hf...
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
2024-05-30 21:05:09 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.00s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.03it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.04it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.01it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.26it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
2024-05-30 21:05:15 | INFO | artifacte_rm_score | Loading dataset from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/artifacts/human...
2024-05-30 21:05:15 | INFO | artifacte_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/artifacts_single_narrative_scale10.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:11, 11.29s/it]Evaluating RM: : 2it [00:19,  9.69s/it]Evaluating RM: : 3it [00:29,  9.82s/it]Evaluating RM: : 4it [00:42, 11.04s/it]Evaluating RM: : 5it [00:53, 10.79s/it]Evaluating RM: : 6it [01:05, 11.35s/it]Evaluating RM: : 7it [01:18, 11.72s/it]Evaluating RM: : 8it [01:29, 11.79s/it]Evaluating RM: : 9it [01:40, 11.32s/it]Evaluating RM: : 10it [01:52, 11.75s/it]Evaluating RM: : 11it [02:02, 11.17s/it]Evaluating RM: : 12it [02:18, 12.62s/it]Evaluating RM: : 13it [02:31, 12.55s/it]Evaluating RM: : 14it [02:41, 11.78s/it]Evaluating RM: : 15it [02:51, 11.22s/it]Evaluating RM: : 16it [02:59, 10.36s/it]Evaluating RM: : 17it [03:06,  9.39s/it]Evaluating RM: : 18it [03:16,  9.45s/it]Evaluating RM: : 19it [03:25,  9.48s/it]Evaluating RM: : 20it [03:36,  9.89s/it]Evaluating RM: : 21it [03:47, 10.30s/it]Evaluating RM: : 22it [03:57, 10.10s/it]Evaluating RM: : 23it [04:08, 10.43s/it]Evaluating RM: : 24it [04:18, 10.32s/it]Evaluating RM: : 25it [04:29, 10.32s/it]Evaluating RM: : 26it [04:37,  9.92s/it]Evaluating RM: : 27it [04:50, 10.73s/it]Evaluating RM: : 28it [04:59, 10.04s/it]Evaluating RM: : 29it [05:09, 10.21s/it]Evaluating RM: : 30it [05:22, 10.97s/it]Evaluating RM: : 31it [05:38, 12.48s/it]Evaluating RM: : 32it [05:49, 12.13s/it]Evaluating RM: : 33it [05:59, 11.53s/it]Evaluating RM: : 34it [06:09, 10.94s/it]Evaluating RM: : 35it [06:17, 10.01s/it]Evaluating RM: : 36it [06:24,  9.24s/it]Evaluating RM: : 37it [06:33,  9.03s/it]Evaluating RM: : 38it [06:46, 10.25s/it]Evaluating RM: : 39it [06:54,  9.68s/it]Evaluating RM: : 40it [07:00,  8.39s/it]Evaluating RM: : 41it [07:15, 10.42s/it]Evaluating RM: : 42it [07:32, 12.55s/it]Evaluating RM: : 43it [07:41, 11.46s/it]Evaluating RM: : 44it [07:53, 11.44s/it]Evaluating RM: : 45it [08:03, 11.06s/it]Evaluating RM: : 46it [08:16, 11.77s/it]Evaluating RM: : 47it [08:26, 11.06s/it]Evaluating RM: : 48it [08:39, 11.87s/it]Evaluating RM: : 49it [08:48, 10.99s/it]Evaluating RM: : 50it [08:57, 10.26s/it]Evaluating RM: : 51it [09:05,  9.51s/it]Evaluating RM: : 52it [09:16, 10.00s/it]Evaluating RM: : 53it [09:28, 10.77s/it]Evaluating RM: : 54it [09:39, 10.79s/it]Evaluating RM: : 55it [09:49, 10.61s/it]Evaluating RM: : 56it [09:59, 10.35s/it]Evaluating RM: : 57it [10:10, 10.59s/it]Evaluating RM: : 58it [10:23, 11.37s/it]Evaluating RM: : 59it [10:39, 12.57s/it]Evaluating RM: : 60it [10:48, 11.56s/it]Evaluating RM: : 61it [10:59, 11.44s/it]Evaluating RM: : 62it [11:09, 10.89s/it]Evaluating RM: : 63it [11:18, 10.36s/it]Evaluating RM: : 64it [11:27,  9.88s/it]Evaluating RM: : 65it [11:43, 11.87s/it]Evaluating RM: : 66it [11:53, 11.28s/it]Evaluating RM: : 67it [12:03, 10.91s/it]Evaluating RM: : 68it [12:15, 11.12s/it]Evaluating RM: : 69it [12:23, 10.19s/it]Evaluating RM: : 70it [12:34, 10.60s/it]Evaluating RM: : 71it [12:49, 11.77s/it]Evaluating RM: : 72it [13:00, 11.67s/it]Evaluating RM: : 73it [13:07, 10.27s/it]Evaluating RM: : 74it [13:16,  9.82s/it]Evaluating RM: : 75it [13:30, 11.03s/it]Evaluating RM: : 76it [13:43, 11.58s/it]Evaluating RM: : 77it [13:52, 10.82s/it]Evaluating RM: : 78it [14:01, 10.33s/it]Evaluating RM: : 79it [14:13, 10.98s/it]Evaluating RM: : 80it [14:23, 10.62s/it]Evaluating RM: : 81it [14:37, 11.52s/it]Evaluating RM: : 82it [14:47, 11.08s/it]Evaluating RM: : 83it [14:59, 11.52s/it]Evaluating RM: : 84it [15:11, 11.59s/it]Evaluating RM: : 85it [15:21, 11.14s/it]Evaluating RM: : 86it [15:33, 11.41s/it]Evaluating RM: : 87it [15:44, 11.05s/it]Evaluating RM: : 88it [15:51,  9.96s/it]Evaluating RM: : 89it [16:01,  9.96s/it]Evaluating RM: : 90it [16:10,  9.71s/it]Evaluating RM: : 91it [16:21, 10.22s/it]Evaluating RM: : 92it [16:32, 10.43s/it]Evaluating RM: : 93it [16:40,  9.62s/it]Evaluating RM: : 94it [16:51, 10.11s/it]Evaluating RM: : 95it [17:01,  9.88s/it]Evaluating RM: : 96it [17:10,  9.74s/it]Evaluating RM: : 97it [17:19,  9.56s/it]Evaluating RM: : 98it [17:28,  9.40s/it]Evaluating RM: : 99it [17:39,  9.89s/it]Evaluating RM: : 100it [17:51, 10.39s/it]Evaluating RM: : 100it [17:51, 10.71s/it]
2024-05-30 21:23:07 | INFO | artifacte_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/artifacts/human
