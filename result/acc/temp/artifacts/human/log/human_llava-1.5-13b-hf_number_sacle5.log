2024-05-30 20:16:27 | INFO | artifacte_rm_score | Loading reward model form llava-1.5-13b-hf...
/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.29it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.40it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.48it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.48it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.48it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.79it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.59it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-05-30 20:16:40 | INFO | artifacte_rm_score | Loading dataset from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/artifacts/human...
2024-05-30 20:16:40 | INFO | artifacte_rm_score | Loading prompt template from /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/prompts/artifacts_single_number_scale5.txt
Evaluating RM: : 0it [00:00, ?it/s]Evaluating RM: : 1it [00:14, 14.69s/it]Evaluating RM: : 2it [00:26, 12.87s/it]Evaluating RM: : 3it [00:40, 13.34s/it]Evaluating RM: : 4it [00:52, 12.78s/it]Evaluating RM: : 5it [01:03, 12.32s/it]Evaluating RM: : 6it [01:16, 12.54s/it]Evaluating RM: : 7it [01:27, 12.01s/it]Evaluating RM: : 8it [01:42, 12.92s/it]Evaluating RM: : 9it [01:56, 13.19s/it]Evaluating RM: : 10it [02:10, 13.44s/it]Evaluating RM: : 11it [02:23, 13.41s/it]Evaluating RM: : 12it [02:36, 13.23s/it]Evaluating RM: : 13it [02:46, 12.39s/it]Evaluating RM: : 14it [02:58, 12.22s/it]Evaluating RM: : 15it [03:11, 12.37s/it]Evaluating RM: : 16it [03:23, 12.31s/it]Evaluating RM: : 17it [03:36, 12.52s/it]Evaluating RM: : 18it [03:51, 13.21s/it]Evaluating RM: : 19it [04:02, 12.62s/it]Evaluating RM: : 20it [04:16, 13.04s/it]Evaluating RM: : 21it [04:29, 12.94s/it]Evaluating RM: : 22it [04:40, 12.45s/it]Evaluating RM: : 23it [04:52, 12.29s/it]Evaluating RM: : 24it [05:03, 11.90s/it]Evaluating RM: : 25it [05:16, 12.35s/it]Evaluating RM: : 26it [05:29, 12.28s/it]Evaluating RM: : 27it [05:42, 12.72s/it]Evaluating RM: : 28it [05:55, 12.80s/it]Evaluating RM: : 29it [06:08, 12.93s/it]Evaluating RM: : 30it [06:18, 12.05s/it]Evaluating RM: : 31it [06:32, 12.41s/it]Evaluating RM: : 32it [06:43, 12.15s/it]Evaluating RM: : 33it [06:56, 12.44s/it]Evaluating RM: : 34it [07:08, 12.14s/it]Evaluating RM: : 35it [07:18, 11.44s/it]Evaluating RM: : 36it [07:32, 12.17s/it]Evaluating RM: : 37it [07:42, 11.68s/it]Evaluating RM: : 38it [07:53, 11.50s/it]Evaluating RM: : 39it [08:04, 11.46s/it]Evaluating RM: : 40it [08:17, 11.78s/it]Evaluating RM: : 41it [08:30, 12.16s/it]Evaluating RM: : 42it [08:46, 13.43s/it]Evaluating RM: : 43it [08:59, 13.16s/it]Evaluating RM: : 44it [09:13, 13.49s/it]Evaluating RM: : 45it [09:23, 12.45s/it]Evaluating RM: : 46it [09:38, 13.02s/it]Evaluating RM: : 47it [09:49, 12.59s/it]Evaluating RM: : 48it [10:04, 13.19s/it]Evaluating RM: : 49it [10:15, 12.62s/it]Evaluating RM: : 50it [10:26, 12.22s/it]Evaluating RM: : 51it [10:39, 12.20s/it]Evaluating RM: : 52it [10:51, 12.18s/it]Evaluating RM: : 53it [11:01, 11.70s/it]Evaluating RM: : 54it [11:15, 12.34s/it]Evaluating RM: : 55it [11:25, 11.67s/it]Evaluating RM: : 56it [11:35, 11.16s/it]Evaluating RM: : 57it [11:47, 11.27s/it]Evaluating RM: : 58it [11:57, 11.04s/it]Evaluating RM: : 59it [12:08, 11.07s/it]Evaluating RM: : 60it [12:22, 11.86s/it]Evaluating RM: : 61it [12:35, 12.05s/it]Evaluating RM: : 62it [12:47, 12.11s/it]Evaluating RM: : 63it [12:59, 12.06s/it]Evaluating RM: : 64it [13:11, 12.03s/it]Evaluating RM: : 65it [13:23, 11.98s/it]Evaluating RM: : 66it [13:33, 11.46s/it]Evaluating RM: : 67it [13:48, 12.47s/it]Evaluating RM: : 68it [14:00, 12.51s/it]Evaluating RM: : 69it [14:11, 12.04s/it]Evaluating RM: : 70it [14:22, 11.57s/it]Evaluating RM: : 71it [14:35, 11.96s/it]Evaluating RM: : 72it [14:48, 12.37s/it]Evaluating RM: : 73it [15:01, 12.69s/it]Evaluating RM: : 74it [15:14, 12.71s/it]Evaluating RM: : 75it [15:28, 13.02s/it]Evaluating RM: : 76it [15:40, 12.71s/it]Evaluating RM: : 77it [15:50, 11.98s/it]Evaluating RM: : 78it [16:05, 12.92s/it]Evaluating RM: : 79it [16:20, 13.46s/it]Evaluating RM: : 80it [16:32, 13.09s/it]Evaluating RM: : 81it [16:45, 13.00s/it]Evaluating RM: : 82it [16:58, 13.11s/it]Evaluating RM: : 83it [17:09, 12.50s/it]Evaluating RM: : 84it [17:24, 13.23s/it]Evaluating RM: : 85it [17:37, 13.11s/it]Evaluating RM: : 86it [17:50, 13.18s/it]Evaluating RM: : 87it [18:02, 12.81s/it]Evaluating RM: : 88it [18:15, 12.64s/it]Evaluating RM: : 89it [18:30, 13.50s/it]Evaluating RM: : 90it [18:43, 13.30s/it]Evaluating RM: : 91it [18:56, 13.22s/it]Evaluating RM: : 92it [19:09, 13.02s/it]Evaluating RM: : 93it [19:22, 13.19s/it]Evaluating RM: : 94it [19:34, 12.76s/it]Evaluating RM: : 95it [19:46, 12.62s/it]Evaluating RM: : 96it [19:59, 12.76s/it]Evaluating RM: : 97it [20:15, 13.66s/it]Evaluating RM: : 98it [20:28, 13.52s/it]Evaluating RM: : 99it [20:40, 13.12s/it]Evaluating RM: : 100it [20:53, 13.01s/it]Evaluating RM: : 100it [20:53, 12.54s/it]
2024-05-30 20:37:33 | INFO | artifacte_rm_score | Saving result to /cpfs01/user/duyichao/workspace/LLM_RLAIF/MM-Reward/eval/results/artifacts/human
